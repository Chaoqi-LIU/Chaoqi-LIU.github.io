# Projects

## Refining the Additive Random Noise Detection Method for Adversarial Examples   
*December 2020 -- May 2021*

**Abstract** \
Natural images are virtually surrounded by low-density misclassified regions that can be efficiently discovered by gradient-guided search — enabling the generation of adversarial images — images that an attacker has intentionally designed to cause machine learning models to make mistakes. In this paper, I propose a simple change to the existing additive random noise detection method — a test time method to distinguish adversarial images by testing the robustness of input images. I propose the Ensemble Method of additive random noise detection method where I demonstrate that by testing with different combinations of noise radius (variance) of zero-mean Gaussian noise, there is an increase in detection rate of adversarial images (true positive rate increases when false positive rate is fixed).



[back](https://chaoqi-liu.github.io/experience/overview)
